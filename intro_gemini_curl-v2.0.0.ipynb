{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ijGzTHJJUCPY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPC2X_a9ErW7"
   },
   "source": [
    "# Getting Started with the Gemini API in Vertex AI with cURL / REST API\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_curl.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>       \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_curl.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "   <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/4jeQxSk\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_curl.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f0cc0f48513b"
   },
   "source": [
    "| Author(s) |\n",
    "| --- |\n",
    "| [Eric Dong](https://github.com/gericdong) |\n",
    "| [Polong Lin](https://github.com/polong-lin) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axauUzNXEl_R"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Introduction to Gemini on Vertex AI**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=YfiLUpNejpE&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/YfiLUpNejpE/maxresdefault.jpg\" alt=\"Introduction to Gemini on Vertex AI\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "In this tutorial, you learn how to use the Vertex AI REST API with cURL commands to interact with the Gemini 2.0 Flash model.\n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "- Text generation\n",
    "- Streaming text generation\n",
    "- Chat\n",
    "- Function Calling\n",
    "- Multimodal Input\n",
    "- Controlled generation\n",
    "- Search as a tool\n",
    "- Code execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJf9sLIIEl_S"
   },
   "source": [
    "### Costs\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "- Vertex AI\n",
    "\n",
    "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D50ekWXjEl_S"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f7c203ffaa1"
   },
   "source": [
    "### Install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4e66b2f6d36f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "!sudo apt install -q jq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restart current runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which will restart the current kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restart kernel after installs so that your environment can access the new packages\n",
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmWOrTJ3gx13"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "If you are running this notebook on Google Colab, run the following cell to authenticate your environment.\n",
    "\n",
    "This step is not required if you are using [Vertex AI Workbench](https://cloud.google.com/vertex-ai-workbench)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NyKGtVQjgx13",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Additional authentication is required for Google Colab\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Authenticate user to Google Cloud\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O6ZGaZlxP9L0"
   },
   "source": [
    "### Set Google Cloud project\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u8IivOG5SqY6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"qwiklabs-gcp-02-2e32d30aa006\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-east4\"  # @param {type:\"string\"}\n",
    "\n",
    "# Import libraries\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please like share & subscribe to Techcps https://www.youtube.com/@techcps\n"
     ]
    }
   ],
   "source": [
    "# Please like share & subscribe to Techcps\n",
    "# YouTube https://www.youtube.com/@techcps\n",
    "\n",
    "print(\"Please like share & subscribe to Techcps https://www.youtube.com/@techcps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "854fbf388e2b"
   },
   "source": [
    "## Use the Gemini 2.0 Flash model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7eeb063ac6d4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.0-flash\"\n",
    "API_HOST = f\"{LOCATION}-aiplatform.googleapis.com\"\n",
    "\n",
    "os.environ[\"API_ENDPOINT\"] = (\n",
    "    f\"{API_HOST}/v1/projects/{PROJECT_ID}/locations/{LOCATION}/publishers/google/models/{MODEL_ID}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZZUVBSzc0cR"
   },
   "source": [
    "## Text generation\n",
    "\n",
    "The `generateContent` method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports. In this example, you send a text prompt and request the model response in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "1979afec8834",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is blue due to a phenomenon called **Rayleigh scattering**. Here's the breakdown:\n",
      "\n",
      "*   **Sunlight and Its Colors:** Sunlight, as we know, appears white. However, white light is actually composed of all the colors of the rainbow (red, orange, yellow, green, blue, indigo, and violet).\n",
      "\n",
      "*   **Entering the Atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (mostly nitrogen and oxygen).\n",
      "\n",
      "*   **Scattering of Light:** This collision causes the sunlight to scatter in different directions. This scattering is more effective at shorter wavelengths (colors with shorter wavelengths are closer to the blue end of the spectrum and colors with longer wavelengths are closer to the red end of the spectrum).\n",
      "\n",
      "*   **Rayleigh Scattering Effect:** Rayleigh scattering is the type of scattering that is most relevant here. Rayleigh scattering states that the amount of scattering is inversely proportional to the fourth power of the wavelength. This means that shorter wavelengths (blue and violet) are scattered much more strongly than longer wavelengths (red and orange). In particular, violet is scattered the most and red the least.\n",
      "\n",
      "*   **Why Blue, Not Violet?** While violet is scattered even more than blue, our eyes are more sensitive to blue light. The sun emits less violet light than blue light, and the upper atmosphere absorbs some violet. These factors combine to make the sky appear blue rather than violet.\n",
      "\n",
      "*   **Sunrise and Sunset:** At sunrise and sunset, the sunlight travels through a longer path in the atmosphere to reach our eyes. Because of this long path, the blue light is scattered away almost completely before it reaches us. Only the longer wavelengths, like red and orange, can make it through, giving us those beautiful sunrise and sunset colors.\n",
      "\n",
      "In summary, the sky is blue because air molecules scatter blue light from the sun more than they scatter other colors.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" },\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"response_modalities\": \"TEXT\",\n",
    "     },\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27701e417da6"
   },
   "source": [
    "### Streaming\n",
    "\n",
    "The Gemini API provides a streaming response mechanism. With this approach, you don't need to wait for the complete response; you can start processing fragments as soon as they're accessible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rzkCij_iS0we",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      " sky is blue\n",
      " because of a phenomenon called **Rayleigh scattering**. Here's a breakdown:\n",
      "\n",
      "*   \n",
      "**Sunlight is white:** While it appears yellow, sunlight is actually made up of\n",
      " all the colors of the rainbow.\n",
      "\n",
      "*   **Entering the atmosphere:** When sunlight enters the Earth's atmosphere, it collides with tiny air molecules (\n",
      "mostly nitrogen and oxygen).\n",
      "\n",
      "*   **Scattering of light:** This collision causes the sunlight to scatter in different directions.\n",
      "\n",
      "*   **Rayleigh scattering:**\n",
      " This type of scattering is more effective at shorter wavelengths (blue and violet) than longer wavelengths (red and orange). This is because shorter wavelengths have higher frequencies, which makes them interact more strongly with the air molecules.\n",
      "\n",
      "*   **Why\n",
      " not violet?** While violet light is scattered even more than blue light, there are a few reasons why we see the sky as blue:\n",
      "    *   **Less violet light in sunlight:** The sun emits slightly less violet light than blue light.\n",
      "\n",
      "    *   **Atmospheric absorption:** The upper atmosphere absorbs some violet light.\n",
      "    *   **Our eyes are more sensitive to blue:** Our eyes are not as sensitive to violet light as they are to blue light.\n",
      "\n",
      "*   **The result:** Because blue light is scattered more than other colors and is also present in\n",
      " a larger amount than violet, it reaches our eyes from all directions, making the sky appear blue.\n",
      "\n",
      "**In summary:** The sky is blue because the air molecules in Earth's atmosphere scatter blue light from the sun more than they scatter other colors.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:streamGenerateContent \\\n",
    " \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": { \"text\": \"Why is the sky blue?\" }\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".[] | .candidates[] | .content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3e56BV7PH9t8"
   },
   "source": [
    "### Model parameters\n",
    "\n",
    "Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Px8hSHhiH9t8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lighthouse keeper, Silas, was a man woven from the sea itself. His skin was tanned and weathered like driftwood, his eyes the grey-green of a storm-tossed wave. He'd spent thirty years tending the beacon on the jagged, isolated Isle of Aethel, a lonely sentinel against the unforgiving Atlantic.\n",
      "\n",
      "Silas wasn't lonely, though. He had the gulls for company, the rhythmic crash of the waves, and the stories whispered on the wind. He knew the sea's moods intimately, its gentle caress and its furious rage. He understood its language, the mournful cry of the foghorn, the urgent slap of the waves against the rocks.\n",
      "\n",
      "One particularly blustery autumn evening, a storm raged with a ferocity Silas hadn't witnessed in decades. The wind howled like a banshee, tearing at the lighthouse walls. The waves, monstrous and black, clawed at the base of the tower, threatening to swallow it whole.\n",
      "\n",
      "As Silas meticulously maintained the lamp, ensuring its unwavering beam cut through the tempest, he heard a sound above the storm's roar. A faint, desperate cry.\n",
      "\n",
      "He strained his ears, dismissing it as the wind playing tricks. But it came again, clearer this time, a human voice lost in the maelstrom.\n",
      "\n",
      "Silas, his heart pounding against his ribs, grabbed his oilskins and descended the winding stairs. He knew it was madness to venture out in such weather, but he couldn't ignore the plea.\n",
      "\n",
      "He fought his way through the gale, the wind trying to rip him from his feet. He followed the sound, his lantern casting a feeble circle of light in the swirling darkness.\n",
      "\n",
      "Finally, he found her. A young woman, clinging to a piece of wreckage, her face pale and etched with terror. She was barely conscious, her clothes soaked and heavy.\n",
      "\n",
      "Silas, with the strength born of years battling the elements, hauled her onto his back and stumbled back towards the lighthouse. It was a grueling journey, each step a victory against the storm's relentless assault.\n",
      "\n",
      "He managed to get her inside, wrapped her in warm blankets, and coaxed hot tea down her throat. Slowly, she began to recover.\n",
      "\n",
      "Her name was Elara, and she was a marine biologist, studying the migratory patterns of whales. Her research vessel had been caught in the storm and capsized. She was the only survivor.\n",
      "\n",
      "For days, they were stranded on the island, the storm refusing to abate. Silas tended to Elara, sharing his meager rations and his stories of the sea. He taught her the names of the seabirds, the secrets of the tides, and the language of the waves.\n",
      "\n",
      "Elara, in turn, shared her knowledge of the ocean's depths, the intricate ecosystems hidden beneath the surface, the wonders of the marine world. She showed him the beauty he had taken for granted, the delicate dance of life that thrived even in the harshest environments.\n",
      "\n",
      "As the storm finally subsided and the sun broke through the clouds, a rescue ship arrived. Elara was safe, but she was leaving a piece of herself behind.\n",
      "\n",
      "Before she boarded the ship, she turned to Silas, her eyes filled with gratitude. \"Thank you,\" she said, her voice choked with emotion. \"You saved my life. And you showed me the true heart of the sea.\"\n",
      "\n",
      "Silas smiled, a rare and precious sight. \"The sea has a way of bringing people together,\" he said, his voice raspy from years of shouting over the wind.\n",
      "\n",
      "Elara promised to return, and Silas knew, in his heart, that she would. He watched the ship disappear over the horizon, then turned back to his lighthouse, the familiar beam cutting through the twilight.\n",
      "\n",
      "The Isle of Aethel was still lonely, but it wasn't the same kind of lonely. It was a loneliness filled with the echo of laughter, the warmth of shared stories, and the knowledge that even in the vast, unforgiving ocean, connection was possible. The sea, Silas knew, had given him more than just a life; it had given him a friend. And that, he realized, was a treasure worth more than all the gold in the world.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\"text\": \"Tell me a story.\"}\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4-XhmPn_Pb-"
   },
   "source": [
    "### Chat\n",
    "\n",
    "The Gemini API supports natural multi-turn conversations and is ideal for text tasks that require back-and-forth interactions.\n",
    "\n",
    "Specify the `role` field only if the content represents a turn in a conversation. You can set `role` to one of the following values: `user`, `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "YqSQSK-K-KVU",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, since we're just starting, the first order of business depends on what we're trying to achieve! To help me understand, could you tell me:\n",
      "\n",
      "*   **What is the purpose of this meeting/conversation?** (e.g., planning a project, discussing a problem, brainstorming ideas, etc.)\n",
      "*   **Is there a specific agenda or topic you'd like to start with?**\n",
      "\n",
      "Once I know what we're here to do, I can suggest a good starting point.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": [\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"model\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"Hello! I am glad you could both make it.\" }\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [\n",
    "          { \"text\": \"So what is the first order of business?\" }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5f0f5fe3b331"
   },
   "source": [
    "### Function calling\n",
    "\n",
    "Function calling lets you create a description of a function in their code, then pass that description to a language model in a request. This sample is an example of passing in a description of a function that returns information about where a movie is playing. Several function declarations are included in the request, such as `find_movies` and `find_theaters`.\n",
    "\n",
    "Learn more about [function calling](https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "680b11b0ba4c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"find_theaters\",\n",
      "  \"args\": {\n",
      "    \"location\": \"Mountain View, CA\",\n",
      "    \"movie\": \"Barbie\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "      \"text\": \"Which theaters in Mountain View show Barbie movie?\"\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "    {\n",
    "      \"function_declarations\": [\n",
    "        {\n",
    "          \"name\": \"find_movies\",\n",
    "          \"description\": \"find movie titles currently playing in theaters based on any description, genre, title words, etc.\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any kind of description including category or genre, title words, attributes, etc.\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"description\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"find_theaters\",\n",
    "          \"description\": \"find theaters based on location and optionally movie title which are is currently playing in theaters\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"get_showtimes\",\n",
    "          \"description\": \"Find the start times for movies playing in a specific theater\",\n",
    "          \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"location\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city and state, e.g. San Francisco, CA or a zip code e.g. 95616\"\n",
    "              },\n",
    "              \"movie\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Any movie title\"\n",
    "              },\n",
    "              \"theater\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Name of theater\"\n",
    "              },\n",
    "              \"date\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Date for requested showtime\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"location\",\n",
    "              \"movie\",\n",
    "              \"theater\",\n",
    "              \"date\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].functionCall\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R3g5n23lDtsN"
   },
   "source": [
    "## Multimodal input\n",
    "\n",
    "Gemini is a multimodal model that supports adding image and video in text or chat prompts for a text response.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTfL2DDch4Lp"
   },
   "source": [
    "### Download an image from Google Cloud Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KmtWSNLtJ7oD",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg...\n",
      "/ [1 files][ 17.4 KiB/ 17.4 KiB]                                                \n",
      "Operation completed over 1 objects/17.4 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\" ./image.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlyyaPgmhpyv"
   },
   "source": [
    "### Generate text from a local image\n",
    "\n",
    "Specify the [base64](https://en.wikipedia.org/wiki/Base64) encoding of the image or video to include inline in the prompt and the `mime_type` field. The supported [MIME types](https://en.wikipedia.org/wiki/Media_type) for images include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-uqZ-RWdtdit",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, the image shows a cat. It appears to be a tabby cat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Encode image data in base64\n",
    "image_file=\"image.jpg\"\n",
    "if [[ -f \"$image_file\" ]]; then\n",
    "  if command -v base64 &> /dev/null; then\n",
    "    # base64 is available\n",
    "    if [[ \"$(uname -s)\" == \"Darwin\" ]]; then\n",
    "      # macOS -b 0 to avoid line wrapping\n",
    "      data=$(base64 -b 0 -i \"$image_file\")\n",
    "    else\n",
    "      # Linux -w 0 to avoid line wrapping\n",
    "      data=$(base64 -w 0 \"$image_file\")\n",
    "    fi\n",
    "  else\n",
    "    echo \"Error: base64 command not found.\"\n",
    "    exit 1\n",
    "  fi\n",
    "else\n",
    "  echo \"Error: Image file '$image_file' not found.\"\n",
    "  exit 1\n",
    "fi\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d \"{\n",
    "      'contents': {\n",
    "        'role': 'USER',\n",
    "        'parts': [\n",
    "          {\n",
    "            'text': 'Is it a cat?'\n",
    "          },\n",
    "          {\n",
    "            'inline_data': {\n",
    "              'data': '${data}',\n",
    "              'mime_type':'image/jpeg'\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "       }\n",
    "    }\" 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKr-BklmhjgP"
   },
   "source": [
    "### Generate text from an image on Google Cloud Storage\n",
    "\n",
    "Specify the Cloud Storage URI of the image to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported image MIME types include `image/png` and `image/jpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "43pQE3_z3OjG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a description of the image:\n",
      "\n",
      "**Overall Impression:**\n",
      "\n",
      "The image shows a tabby cat standing in the snow. The cat is the main subject and is in focus, while the snowy background is slightly blurred.\n",
      "\n",
      "**Cat's Appearance:**\n",
      "\n",
      "*   **Coat:** The cat has a classic tabby coat pattern, with dark brown or black stripes on a lighter brown background.\n",
      "*   **Eyes:** The cat has yellow or golden eyes.\n",
      "*   **Pose:** The cat is standing with one paw slightly raised, as if it's about to take a step. It's looking directly at the viewer with a curious or alert expression.\n",
      "*   **Build:** The cat appears to be of average build, neither overly thin nor overweight.\n",
      "\n",
      "**Background:**\n",
      "\n",
      "*   The background is entirely snow-covered.\n",
      "*   There are some subtle textures and variations in the snow, suggesting it might be a path or a field.\n",
      "*   The background is out of focus, which helps to emphasize the cat as the main subject.\n",
      "\n",
      "**Overall Tone:**\n",
      "\n",
      "The image has a natural and slightly cold feel due to the snow. The cat's alert expression adds a touch of curiosity and liveliness to the scene.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Describe this image\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"image/png\",\n",
    "            \"file_uri\": \"gs://cloud-samples-data/generative-ai/image/320px-Felis_catus-cat_on_snow.jpg\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"generation_config\": {\n",
    "      \"temperature\": 0.2,\n",
    "      \"top_p\": 0.1,\n",
    "      \"top_k\": 16,\n",
    "      \"max_output_tokens\": 2048,\n",
    "      \"candidate_count\": 1,\n",
    "      \"stop_sequences\": []\n",
    "    },\n",
    "    \"safety_settings\": {\n",
    "      \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "      \"threshold\": \"BLOCK_LOW_AND_ABOVE\"\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TVF4vHuBOD8N"
   },
   "source": [
    "### Generate text from a video file\n",
    "\n",
    "Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the `mime_type` field. The supported MIME types for video include `video/mp4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "F8kS5p0l_uHE",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here are the answers to your questions based on the information in the video:\n",
      "\n",
      "*   **Profession:** Saeka Shimada is a photographer.\n",
      "*   **Phone Features:** The video highlights the phone's video boost feature, specifically how the Night Sight mode can be activated in low light to improve image quality.\n",
      "*   **City:** The video was recorded in Tokyo, Japan.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d \\\n",
    "'{\n",
    "    \"contents\": {\n",
    "      \"role\": \"USER\",\n",
    "      \"parts\": [\n",
    "        {\n",
    "          \"text\": \"Answer the following questions using the video only. What is the profession of the main person? What are the main features of the phone highlighted? Which city was this recorded in?\"\n",
    "        },\n",
    "        {\n",
    "          \"file_data\": {\n",
    "            \"mime_type\": \"video/mp4\",\n",
    "            \"file_uri\": \"gs://github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
    "          }\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  }' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "133ddb1bc7ff"
   },
   "source": [
    "### Controlled Generation\n",
    "\n",
    "Controlled generation allows you to define a response schema to specify the structure of a model's output, the field names, and the expected data type for each field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "40db1e8d9061",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"recipe_name\": \"Chocolate Chip Cookies\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": {\n",
    "      \"role\": \"user\",\n",
    "      \"parts\": {\n",
    "        \"text\": \"List a few popular cookie recipes.\"\n",
    "      }\n",
    "    },\n",
    "    \"generationConfig\": {\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_schema\": {\"type\": \"object\", \"properties\": {\"recipe_name\": {\"type\": \"string\"}}}\n",
    "    },\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebcbb1533401"
   },
   "source": [
    "## Search as a tool\n",
    "\n",
    "Using Grounding with Google Search, you can improve the accuracy and recency of responses from the model. Starting with Gemini 2.0, Google Search is available as a tool. This means that the model can decide when to use Google Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "a3d8a66bfb3c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather in San Jose, CA today, June 2, 2025, is sunny with a temperature of 70°F (21°C), but it feels like 76°F (24°C). The humidity is around 52% and there is a 0% chance of rain. The forecast for today is sunny during the day and clear at night, with temperatures between 52°F (11°C) and 79°F (26°C).\n",
      "\n",
      "[\n",
      "  {\n",
      "    \"web\": {\n",
      "      \"uri\": \"https://www.google.com/search?q=weather+in+San Jose,+CA\",\n",
      "      \"title\": \"Weather information for locality: San Jose, administrative_area: CA\",\n",
      "      \"domain\": \"google.com\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "    \"contents\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"parts\": [\n",
    "                {\n",
    "                    \"text\": \"What is the weather today in San Jose CA?\"\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "  ],\n",
    "  \"tools\": {\n",
    "     \"google_search\": {}\n",
    "  },\n",
    "  \"generationConfig\": {\n",
    "      \"response_modalities\": \"TEXT\"\n",
    "  }\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[].text\" response.json\n",
    "jq -r \".candidates[].groundingMetadata.groundingChunks\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37223c8e3133"
   },
   "source": [
    "### Code Execution\n",
    "\n",
    "The Gemini API code execution feature enables the model to generate and run Python code and learn iteratively from the results until it arrives at a final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7cebe2cd31c1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Okay, I can help with that. First, I'll calculate the 20th Fibonacci number, and then I'll find the nearest palindrome to it.\\n\\n\"\n",
      "}\n",
      "{\n",
      "  \"executableCode\": {\n",
      "    \"language\": \"PYTHON\",\n",
      "    \"code\": \"def fibonacci(n):\\n    if n <= 0:\\n        return 0\\n    elif n == 1:\\n        return 1\\n    else:\\n        a, b = 0, 1\\n        for _ in range(2, n + 1):\\n            a, b = b, a + b\\n        return b\\n\\nfib_20 = fibonacci(20)\\nprint(f'{fib_20=}')\\n\\ndef nearest_palindrome(n):\\n    s = str(n)\\n    l = len(s)\\n    mid = (l - 1) // 2\\n\\n    # Left side\\n    left = s[:mid + 1]\\n\\n    # Generate palindrome candidates\\n    if l % 2 == 0:\\n        palindrome1 = left + left[::-1]\\n    else:\\n        palindrome1 = left + left[:-1][::-1]\\n\\n    palindrome1 = int(palindrome1)\\n\\n    if palindrome1 > n:\\n      palindrome2 = str(int(left) -1)\\n      if len(palindrome2) < len(left):\\n        palindrome2 = \\\"9\\\"*(len(s)-1)\\n      else:\\n        if l % 2 == 0:\\n            palindrome2 = palindrome2 + palindrome2[::-1]\\n        else:\\n            palindrome2 = palindrome2 + palindrome2[:-1][::-1]\\n      palindrome2 = int(palindrome2)\\n    else:\\n      palindrome2 = str(int(left) + 1)\\n      if len(palindrome2) > len(left):\\n        palindrome2 = \\\"1\\\" + \\\"0\\\"*(len(s))\\n      else:\\n        if l % 2 == 0:\\n            palindrome2 = palindrome2 + palindrome2[::-1]\\n        else:\\n            palindrome2 = palindrome2 + palindrome2[:-1][::-1]\\n      palindrome2 = int(palindrome2)\\n    \\n    \\n    if abs(palindrome1 - n) <= abs(palindrome2 - n):\\n        return palindrome1\\n    else:\\n        return palindrome2\\n\\n\\nnearest_pal = nearest_palindrome(fib_20)\\nprint(f'{nearest_pal=}')\\n\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"codeExecutionResult\": {\n",
      "    \"outcome\": \"OUTCOME_OK\",\n",
      "    \"output\": \"fib_20=6765\\nnearest_pal=6776\\n\"\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"text\": \"The 20th Fibonacci number is 6765. The nearest palindrome to 6765 is 6776.\\n\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "curl -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  https://${API_ENDPOINT}:generateContent \\\n",
    "  -d '{\n",
    "  \"contents\": {\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": {\n",
    "      \"text\": \"Calculate 20th fibonacci number. Then find the nearest palindrome to it.\"\n",
    "    }\n",
    "  },\n",
    "  \"tools\": [\n",
    "      {\"code_execution\": {},}\n",
    "  ]\n",
    "}' 2>/dev/null >response.json\n",
    "\n",
    "jq -r \".candidates[].content.parts[]\" response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6301d8abe89d"
   },
   "source": [
    "## What's next\n",
    "\n",
    "- Explore other notebooks in the [Google Cloud Generative AI GitHub repository](https://github.com/GoogleCloudPlatform/generative-ai).\n",
    "- Explore AI models in [Model Garden](https://cloud.google.com/vertex-ai/generative-ai/docs/model-garden/explore-models)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "intro_gemini_curl.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
